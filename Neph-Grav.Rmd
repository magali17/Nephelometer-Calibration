---
title: "Nephelometer Data Exploration"
#author: "Magali Blanco"
#date:  "10/9/17"
output: word_document
---
 larger ggplot axes text? 
 + theme(text = element_text(size=20))
 
 
```{r global_options, include=F, echo=F}
knitr::opts_chunk$set(fig.width=7, fig.height=6, echo=F, include=F, warning=F, message=F )

alpha.val <- 0.1

```

```{r libraries}
library(knitr)
library(ggplot2)
#library(ggforce)
library(plotly)
library(gridExtra)
library(ggplus)  # need?
#library(data.table)
library(lubridate)
library(readr)
library(clipr)  #copy to clipboard fn
#read in data
library(readr)
library(readxl)
library(reshape2)

```

```{r fun: multiplot}
# Multiple plot function
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

```

```{r fn: summary.fn}
summary.fn <- function(df){
  #df <- grav
  summary1 <- data.frame(Min = min(df$Daily24HourAvg),
                       Q1 = quantile(df$Daily24HourAvg, 0.25)[[1]],
                       Median= quantile(df$Daily24HourAvg, 0.5)[[1]],
                       Mean= round(mean(df$Daily24HourAvg), 1),
                       Q3 = quantile(df$Daily24HourAvg, 0.75)[[1]],
                       Max = max(df$Daily24HourAvg)) 
print(summary1)
  }
```

```{r fn: GM, GSD}
gm<-function(x){
    rslt<-exp(mean(log(x))) 
    return(rslt)
    }

gsd<-function(x){
    rslt<-exp(sqrt(var(log(x))))
    #same: rslt <- exp(sd(log(x))) 
    return(rslt)
    }


#? gsd = 
```

```{r DATA MERGING}
#upload & merge data
QmuCodes <- read_excel("~/Everything/School/PhD_UW/Courses/1. Aut 2017/ENVH 595 Rotation A/data-cleanup/Datasets/UWPSCAAqueries/z. Methods - QMU codes.xlsx")
colnames(QmuCodes)[1] <- "QmuCode"

Stations <- read_excel("~/Everything/School/PhD_UW/Courses/1. Aut 2017/ENVH 595 Rotation A/data-cleanup/Datasets/UWPSCAAqueries/z. Stations for UW.xlsx", 
    col_types = c("text", "text", "text", 
        "date", "date", "text", "text", "text", 
        "text", "numeric", "numeric", "numeric", 
        "text", "numeric", "numeric", "numeric", 
        "numeric", "text", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric"))

RH <- read_excel("~/Everything/School/PhD_UW/Courses/1. Aut 2017/ENVH 595 Rotation A/data-cleanup/Datasets/UWPSCAAqueries/tr0045_rh.xlsx", 
    col_types = c("date", "numeric", "numeric", 
        "numeric"))
colnames(RH)<- c("ObservedDate", "SeaTac_Temp_C", "SeaTac_RH", "SeaTac_Vis_m")
RH$SeaTac_AbsHum_g_m3 <- (6.112*exp(17.67*RH$SeaTac_Temp_C/(RH$SeaTac_Temp_C+243.5))* RH$SeaTac_RH * 2.1674) / (273.15+ RH$SeaTac_Temp_C)

#merge datasets (ds) w/ QMU data & change "Daily24HourAvg" to ID each ds
PM2.5_BC_UV_data <- read_excel("~/Everything/School/PhD_UW/Courses/1. Aut 2017/ENVH 595 Rotation A/data-cleanup/Datasets/UWPSCAAqueries/PM2_5 and BC and UV data.xlsx", col_types = c("text", "numeric", "date", "numeric"))
PM2.5_BC_UV_data$Source <- "Gravimetric"

light_scattering_data <- read_excel("~/Everything/School/PhD_UW/Courses/1. Aut 2017/ENVH 595 Rotation A/data-cleanup/Datasets/UWPSCAAqueries/LightScattering data.xlsx", col_types = c("text", "text", "date", "numeric"))
light_scattering_data$Source <- "Light Scattering"

PM <- rbind(PM2.5_BC_UV_data,light_scattering_data)
#PM2 <-rbind(PM2.5_BC_UV_data,light_scattering_data,TSP_data, RH.long)

# add QMU, stations data & RH
PM <- merge(merge(merge(PM, QmuCodes, by="QmuCode", all.x=T), Stations, by="StationCode", all.x=T), RH, by="ObservedDate", all.x=T)
PM$PollutantType <- as.factor(PM$PollutantType)
PM$Source <- as.factor(PM$Source)

#check station codes
PM$StationCode[PM$StationCode=="tb"] <- "TB"
PM$StationCode[PM$StationCode=="tc"] <- "TC"
PM$StationCode[PM$StationCode=="td"] <- "TD"
PM$StationCode[PM$StationCode=="te"] <- "TE"
PM$StationCode[PM$StationCode=="tf"] <- "TF"
PM$StationCode[PM$StationCode=="Ck"] <- "CK"
PM$StationCode <- as.factor(PM$StationCode)

#? eliminate Beacon Hill values - unreliable. near water reservoir?
#PM <- PM[PM$StationCode != "BW",]

PM$QmuCode <- as.numeric(PM$QmuCode)

StationUnique <-data.frame(StationCode=sort(unique(PM$StationCode)))
StationUnique$StationNo <- seq(1:length(unique(PM$StationCode)))
PM <- merge(PM, StationUnique, by="StationCode", all = T)

#add columns to ID which stations sample which sources
PM$SamplesGrav <- as.numeric(ifelse(PM$Source=="Gravimetric", 1, 0))
PM$SamplesLS <- as.numeric(ifelse(PM$Source=="Light Scattering", 1, 0)) 

agg1 <- PM[c("ObservedDate", "StationCode", "SamplesGrav",  "SamplesLS")] 
agg.max <- aggregate(data=agg1, cbind(SamplesGrav, SamplesLS) ~ StationCode + ObservedDate, FUN=max)
agg.max$SamlesBoth <- ifelse(agg.max$SamplesGrav==1 & agg.max$SamplesLS==1,1,0)

PM <- PM[!colnames(PM) %in% c("SamplesGrav",  "SamplesLS")]  
PM <- merge(PM, agg.max, by=c("StationCode", "ObservedDate"), all.x=T)

PM$Type <- factor(ifelse(PM$SamplesGrav==1 & PM$SamplesLS==0, "PM2.5", ifelse(PM$SamplesGrav==0 & PM$SamplesLS==1, "light scattering", ifelse(PM$SamplesGrav==1 & PM$SamplesLS==1, "both", NA))))

PM$Type <- factor(PM$Type, levels= c("PM2.5", "light scattering", "both"))
#categorize RH 
PM$RH_category <- factor(ifelse(PM$SeaTac_RH <=25, "0-25", ifelse(PM$SeaTac_RH >25 & PM$SeaTac_RH <=50, "26-50", ifelse(PM$SeaTac_RH >50 & PM$SeaTac_RH <=75, "51-75", "76-100"))))

#categorize absolute humidity 
PM$AH_g_m3_category <- factor(ifelse(PM$SeaTac_AbsHum_g_m3  <=4, "0_4", ifelse(PM$SeaTac_AbsHum_g_m3 >4 & PM$SeaTac_AbsHum_g_m3 <=8, "5_8", ifelse(PM$SeaTac_AbsHum_g_m3 >8 & PM$SeaTac_AbsHum_g_m3 <=12, "9_12", "13_16"))))

#make temp cateogry 
PM$Temp_F <- PM$SeaTac_Temp_C*9/5 + 32
PM$Temp_F_Category <- factor(ifelse(PM$Temp_F <=25, "0-25", ifelse(PM$Temp_F >25 & PM$Temp_F <=50, "26-50", ifelse(PM$Temp_F >50 & PM$Temp_F <=75, "51-75", "76-100"))))

#make year vector
PM$Year <- as.numeric(format(PM$ObservedDate,'%Y')) #, "%Y")

#make season vector
PM$Season <- factor(quarter(PM$ObservedDate), labels = c("winter", "spring", "summer", "fall"))

# remove data w/ BC or UV CMU codes ("V" shape); & nephelometer estimated values (83, 89)
# do this later? after making some plots?
PM2 <- PM
#PM <- PM2
#delete QMU 83, 89 which are nephelometer estimated values 
badQMUs <- c("85", "850", "88", "86", "860", "200", "83", "89") #UV, BC, PAH, neph
PM <- PM[!PM$QmuCode %in% badQMUs,] 

#delete 4th and 5th of july
PM<- PM[format(PM$ObservedDate, "%m-%d") != "07-04" & format(PM$ObservedDate, "%m-%d") != "07-05", ]

#dfs of just grav or ls data
grav <- PM[PM$Source=="Gravimetric" & !is.na(PM$Daily24HourAvg),]
ls <- PM[PM$Source=="Light Scattering" & !is.na(PM$Daily24HourAvg),]
#merged <- Grav.LS

# df of colocated pm2.5 and LS, by date & station
y.source.name = "Light Scattering"
PM.grav <- subset(PM, Source=="Gravimetric" & !is.na(Daily24HourAvg))
colnames(PM.grav)[colnames(PM.grav)=="Daily24HourAvg"] <- "Grav.Avg"
PM.LS <- subset(PM, Source== y.source.name & !is.na(Daily24HourAvg))
colnames(PM.LS)[colnames(PM.LS)=="Daily24HourAvg"] <- "LS.Avg"
Grav.LS <- merge(PM.grav, PM.LS, by=c("ObservedDate", "StationCode", "StationNo", "Location", "Address"))
 
KeepCols <- c("ObservedDate", "StationNo", "QmuCode", "Year") #"StationCode",  "Address", "Location", "Season"
Grav.LS.short <- merge(PM.grav[c(KeepCols, "Grav.Avg")], PM.LS[c(KeepCols, "LS.Avg")], by=c("ObservedDate",  "StationNo", "Year")) # "StationCode","Address", "Location", "Season"

frm.qmus <- c(50, 51)
fem.qmus <- c(110, 114, 68, 78)
dichot.qmus <- c(36)
teom.qmus <- c(82, 92, 93, 102, 106, 107, 115)
bam.qmus <- c(71, 81, 91) 

# Grav.LS$grav.group <- NULL
# Grav.LS[c(Grav.LS$QmuCode.x %in% frm.qmus),"grav.group"] <- "frm"
# Grav.LS[c(Grav.LS$QmuCode.x %in% fem.qmus),c("grav.group")] <- "fem"
# Grav.LS[c(Grav.LS$QmuCode.x %in% dichot.qmus),c("grav.group")] <- "dichot"
# Grav.LS[c(Grav.LS$QmuCode.x %in% teom.qmus),c("grav.group")] <- "teom"
# Grav.LS[c(Grav.LS$QmuCode.x %in% bam.qmus),c("grav.group")] <- "bam"
# Grav.LS$grav.group <- as.factor(Grav.LS$grav.group)


#collocated data by grav method group
frm <- Grav.LS[Grav.LS$QmuCode.x %in% frm.qmus & !is.na(Grav.LS$Grav.Avg), ]
fem <- Grav.LS[Grav.LS$QmuCode.x %in% fem.qmus & !is.na(Grav.LS$Grav.Avg), ]
frm.fem <- Grav.LS[ !is.na(Grav.LS$Grav.Avg) & (Grav.LS$QmuCode.x== 50 | Grav.LS$QmuCode.x== 51 | Grav.LS$QmuCode.x== 100 | Grav.LS$QmuCode.x== 114 | Grav.LS$QmuCode.x== 68 | Grav.LS$QmuCode.x== 78), ]
dichot <- Grav.LS[Grav.LS$QmuCode.x %in% dichot.qmus & !is.na(Grav.LS$Grav.Avg), ]
teom <- Grav.LS[Grav.LS$QmuCode.x %in% teom.qmus & !is.na(Grav.LS$Grav.Avg), ]
bam <- Grav.LS[Grav.LS$QmuCode.x %in% bam.qmus & !is.na(Grav.LS$Grav.Avg), ]

```

GIS project data
```{r GIS project data}
#11/19/17: gravimetric PM data (in Seattle), GM, GSD; median
grav2010_15 <- grav[grav$ObservedDate >= as.POSIXct("2011-01-01") & grav$ObservedDate <=  as.POSIXct("2014-12-31"), c("ObservedDate", "StationNo", "StationCode", "Location", "FinalLat", "FinalLong", "Daily24HourAvg")]

grav2010_15 <- grav2010_15[grav2010_15$Daily24HourAvg >0,]

grav2010_15.2 <- unique(grav2010_15[c("StationCode", "Location", "FinalLat", "FinalLong")])
grav2010_15.2$observations <- rep(NA, length(grav2010_15.2$StationCode))
grav2010_15.2$GM <- rep(NA, length(grav2010_15.2$StationCode))
grav2010_15.2$GSD <- rep(NA, length(grav2010_15.2$StationCode))
grav2010_15.2$Median <- rep(NA, length(grav2010_15.2$StationCode))

for (i in 1:length(grav2010_15.2$StationCode)){
  df <- grav2010_15[grav2010_15$StationCode==grav2010_15.2$StationCode[i] & !is.na(grav2010_15$Daily24HourAvg),]
  
  grav2010_15.2$observations[i] <- length(df$Daily24HourAvg)
  grav2010_15.2$GM[i] <- gm(df$Daily24HourAvg)
  grav2010_15.2$GSD[i] <- gsd(df$Daily24HourAvg)
  grav2010_15.2$Median[i] <- median(df$Daily24HourAvg)
}
#write_csv(grav2010_15.2, "/Users/magaliblanco/Everything/School/PhD_UW/Courses/1. Aut 2017/ENVH 590 GIS/PM Project/WA data/Grav_Stations2.csv")

```

map by sampling type (PM2.5, ls, both)
```{r}
gis <- unique(PM[!is.na(PM$Location),c("StationCode", "Location", "FinalLat", "FinalLong", "Type")])
#write_csv(gis, "/Users/magaliblanco/Everything/School/PhD_UW/Courses/1. Aut 2017/ENVH 595 Rotation A/data-cleanup/Datasets/GIS_map.csv")

```


```{r fun: data availability}
plot.station.v.date <- function(df) {
  alpha.val <- 1.0
  ggplot(data=df, aes(x=ObservedDate, y=StationNo, colour=Type)) + geom_point(alpha=alpha.val) + 
  labs(x="Date", y="Station No.") + theme(legend.position = "bottom", text = element_text(size=20))  
  }
```

# data availability
##station start/end dates
```{r *Unique Stations & samples}
# list of unique Stations & locations
station.loc <- unique(PM[c("StationNo", "StationCode", "Location")])  
station.loc <- station.loc[!is.na(station.loc$Location),]

station.loc$StartDate <- rep(NA, length(station.loc$StationNo))
station.loc$EndDate <- rep(NA, length(station.loc$StationNo))
station.loc$GravSamples <- rep(NA, length(station.loc$StationNo))
station.loc$LSSamples <- rep(NA, length(station.loc$StationNo))

for (i in 1:length(station.loc$StationNo)){
  df <- PM[PM$StationNo==station.loc$StationNo[i], c("ObservedDate", "Daily24HourAvg", "Source")]
  df <- df[!is.na(df$Daily24HourAvg),]
  
  station.loc$GravSamples[i] <- length(df[df$Source=="Gravimetric", "ObservedDate"])
  station.loc$LSSamples[i] <- length(df[df$Source=="Light Scattering", "ObservedDate"])
  
  station.loc$StartDate[i] <- format(min(df$ObservedDate), "%Y-%m-%d")
  station.loc$EndDate[i] <- format(max(df$ObservedDate),"%Y-%m-%d") 
  
}

#write_clip(station.loc)
 
```

```{r *table2 stats by source}
  
table2 <- data.frame(Source=c("Gravimetric Only", "Light Scattering Only", "Collocated"),
                     StartDate=as.Date(c(min(grav$ObservedDate), min(ls$ObservedDate), min(Grav.LS$ObservedDate))), 
                      EndDate=as.Date(c(max(grav$ObservedDate), max(ls$ObservedDate), max(Grav.LS$ObservedDate))),
                     ObservedReadings=c(length(grav$ObservedDate), length(ls$ObservedDate), length(Grav.LS$ObservedDate)), 
                     UniqueStations=c(length(unique(grav$StationCode)),
                                      length(unique(ls$StationCode)),
                                      length(unique(Grav.LS$StationCode)))) #,
                     # UniqueQMUCodes=c(length(unique(grav$QmuCode)),
                     #                  length(unique(ls$QmuCode)),
                     #                  (length(unique(Grav.LS$QmuCode.x)) + length(unique(Grav.LS$QmuCode.y)))))  
table2$YearRange <-round(as.numeric(table2$EndDate - table2$StartDate)/365,1)
table2$MeanReadingsPerYear <- round(table2$ObservedReadings / table2$YearRange)
table2$MeanReadingsPerDay <- round(table2$ObservedReadings / (table2$YearRange*365))
table2$ReadingFreqDys <- c(1,1, NA)

table2 <-table2[c("Source", "StartDate", "EndDate", "YearRange", "ObservedReadings", "MeanReadingsPerYear", "MeanReadingsPerDay", "ReadingFreqDys", "UniqueStations")] #"UniqueQMUCodes"

#kable(table2, caption= "Data Availability by Source", col.names = c("Source", "Start", "End", "YRS", "Smpl", "Avg Smpl/Yr", "Avg Smpl/Dy", "Smpl Freq", "No. Stations", "No. QMUs"))

#write_clip(table2)
```

```{r *Overall_smokestack}
plot.station.v.date(PM)
#ggsave("output/smokestack.png", width = 8, height=4)
```

```{r table1 overall stats}
table1 <-data.frame(StartDate=min(PM$ObservedDate),
                    EndDAte=max(PM$ObservedDate),
                    #DayRange = as.numeric(max(PM$ObservedDate) - min(PM$ObservedDate)),
                    YearRange=round((as.numeric(max(PM$ObservedDate) - min(PM$ObservedDate)))/365,1),
                    Values=length(which(!is.na(PM$Daily24HourAvg))),
                    UniqueStations=length(unique(PM$StationCode)),
                    UniqueQMUCodes=length(unique(PM$QmuCode)))
table1$MeanValuesPerYear <- round(table1$Values / table1$YearRange)
table1$MeanValuesPerDay <- round(table1$Values / (table1$YearRange*365))
table1 <- table1[c(1:4,7:8,5:6)]
#kable(table1, caption="Overall Data Availability", col.names = c("Start", "End", "Yrs", "Smpl", "Avg Smpl/Yr", "Avg Smpl/Dy", "No. Stations", "No. QMUs") )

#write_clip(table1)

#no TSP
PM2 <- PM[PM$Source != "TSP",]

table1b <-data.frame(StartDate=min(PM2$ObservedDate),
                    EndDAte=max(PM2$ObservedDate),
                    #DayRange = as.numeric(max(PM2$ObservedDate) - min(PM2$ObservedDate)),
                    YearRange=round((as.numeric(max(PM2$ObservedDate) - min(PM2$ObservedDate)))/365,1),
                    Values=length(which(!is.na(PM2$Daily24HourAvg))),
                    UniqueStations=length(unique(PM2$StationCode)),
                    UniqueQMUCodes=length(unique(PM2$QmuCode)))
table1b$MeanValuesPerYear <- round(table1b$Values / table1b$YearRange)
table1b$MeanValuesPerDay <- round(table1b$Values / (table1b$YearRange*365))
table1b <- table1b[c(1:4,7:8,5:6)]
#kable(table1b, caption="Overall Data Availability", col.names = c("Start", "End", "Yrs", "Smpl", "Avg Smpl/Yr", "Avg Smpl/Dy", "No. Stations", "No. QMUs") )

#write_clip(table1b)


```

# Time Series
PM2.5 Over Time  
```{r fun: time series}
# time series
plot.pm.v.date <- function(df, y.label){
  ggplot(data = df, aes(x=ObservedDate, y=LS.Avg, colour=StationNo)) + geom_point(alpha=alpha.val) + labs(x="Date", y= y.label, colour="Station No.") +
  theme(legend.position = "bottom") + theme(text = element_text(size=20))  
}

# plot.pm.date.per.station <- function(df.source, y.label){
# df1 <- PM[PM$Source== df.source,]
# uniq.stat <- unique(df1$StationNo)
# 
#  for (i in 1:length(uniq.stat) ) { #length(uniq.stat)
# p <- ggplot(data = df1[df1$StationNo==uniq.stat[i],], aes(x=ObservedDate, y=Daily24HourAvg)) + geom_point(alpha=alpha.val) + labs(x="Date", y= y.label, subtitle = paste("Station", uniq.stat[i])) + theme(legend.position = "bottom") + xlim(min(as.POSIXct(df1$ObservedDate)), max(as.POSIXct(df1$ObservedDate))) + ylim(0, quantile(df1$Daily24HourAvg, 0.9999, na.rm = T))  
# 
# print(p)
#  }}

```

```{r PM2.5byStation, include=F}
plot.pm.v.date(Grav.LS[Grav.LS$Source.x=="Gravimetric",], "PM2.5 (ug/m3)")
plot.pm.v.date(Grav.LS[Grav.LS$Source.x=="Gravimetric",], bquote("" *PM[2.5]~ "("~mu ~g/m^3* ")"))
 
#ggsave("output/Colloc_PM2.5_Time_Series.png", width = 8, height=4)

```

```{r *grav summary.fn}
write_clip(summary.fn(grav))
```

Light Scattering Over Time  
```{r LSbyStation, include=F}
plot.pm.v.date(Grav.LS[Grav.LS$Source.y=="Light Scattering",], "bscat 10e-5")  
#ggsave("output/Colloc_LS_Time_Series.png", width = 8, height=4)

```

```{r *ls summary.fn}
write_clip(summary.fn(ls))
```

# Meteorological Data Summary
```{r *Met Data}
var.list <- c("Min.", "Q1", "Median", "Mean", "Q3", "Max", "NA %") 
Temp_F.var <- rep(NA, length(var.list))
RH.var <- rep(NA, length(var.list))
AH.var <- rep(NA, length(var.list))

met.table.df <- data.frame(var.list, Temp_F.var, RH.var, AH.var)

for (i in 1:(length(var.list)-1)){
  met.table.df[i,"Temp_F.var"] <- round(summary(PM$Temp_F)[[i]])
  met.table.df[i,"RH.var"] <- round(summary(PM$SeaTac_RH)[[i]])
  met.table.df[i,"AH.var"] <- round(summary(PM$SeaTac_AbsHum_g_m3)[[i]],1)

}

(max(RH$ObservedDate) - min(RH$ObservedDate)) # 12891 day diff

# % missing temp & RH values
met.table.df$Temp_F.var[met.table.df$var.list=="NA %"] <- round(length(which(is.na(RH$SeaTac_Temp_C))) / 12891 *100,2)

met.table.df$RH.var[met.table.df$var.list=="NA %"] <- round(length(which(is.na(RH$SeaTac_RH))) / 12891 *100,2)

met.table.df$AH.var[met.table.df$var.list=="NA %"] <- round(length(which(is.na(RH$SeaTac_AbsHum_g_m3 ))) / 12891 *100,2)

write_clip(met.table.df)

```

# Collocated Data Comparison
functions
```{r fun: plot corr, overall}
# OVERALL CORRELATION, colour = PM2.5 QMU code
plot.grav.corr <- function(df){
df1 <- df
lmGravSource <- summary(lm(Grav.Avg~LS.Avg, data=df1))

p1 <- ggplot(data=df1, aes(y=Grav.Avg, x=LS.Avg)) +  geom_point(alpha=alpha.val) + geom_abline(aes(colour="One-to-One", intercept = 0, slope = 1)) + 
  stat_smooth(aes(colour="Best Fit"), method="lm", se=F) + theme(legend.position = "bottom") + 
  labs(y=bquote("" *PM[2.5]~ " (" ~mu~g/m^3* ")"), x= "Light Scattering (bscat)",  subtitle = paste("R2 = ", round(lmGravSource$r.squared,3), ", B0 = ", round(lmGravSource$coefficients[1,1],2), ", B1 = ", round(lmGravSource$coefficients[2,1], 2)), colour="") + theme(text = element_text(size=20))  

#ggplot...aes(colour=as.factor(QmuCode.x))
#labs...colour= paste("Grav Methods", "", sep = "")
print(p1)
} 

```

[test code]
```{r TEST bquote}

# df1 <- frm
# lmGravSource <- summary(lm(Grav.Avg~LS.Avg, data=df1))
# 
# ggplot(data=df1, aes(y=Grav.Avg, x=LS.Avg)) +  geom_point(alpha=alpha.val) + geom_abline(aes(colour="One-to-One", intercept = 0, slope = 1)) + 
#   stat_smooth(aes(colour="Best Fit"), method="lm", se=F) + theme(legend.position = "bottom") + labs(y=bquote("" *PM[2.5]~ " (" ~mu~g/m^3* ")"), x= "Light Scattering (bscat)",  subtitle = paste("R2 = ", round(lmGravSource$r.squared,3), ", B0 = ", round(lmGravSource$coefficients[1,1],2), ", B1 = ", round(lmGravSource$coefficients[2,1], 2)), colour="") + theme(text = element_text(size=20))   

```

table of calibration curves by gravimetric method group
```{r}
length(Grav.LS$ObservedDate)
summary(lm(data=Grav.LS, Grav.Avg~LS.Avg))

length(frm$ObservedDate)
summary(lm(data=frm, Grav.Avg~LS.Avg))

length(fem$ObservedDate)
summary(lm(data=fem, Grav.Avg~LS.Avg))

#both FRM & FEM
length(frm.fem$ObservedDate)
summary(lm(data=frm.fem, Grav.Avg~LS.Avg))

length(dichot$ObservedDate)
summary(lm(data=dichot, Grav.Avg~LS.Avg))

length(teom$ObservedDate)
summary(lm(data=teom, Grav.Avg~LS.Avg))

length(bam$ObservedDate)
summary(lm(data=bam, Grav.Avg~LS.Avg))


```

basic Correlation plots 
```{r corr}
#use all data to calibrate neph
plot.grav.corr(Grav.LS) 
 
#use FRM data to calibrate neph  # R2 = 0.91
plot.grav.corr(frm)
#ggsave("output/frm-neph scatterplot.png", width = 8, height=8)

```

FRM calibrations by met categories
```{r corr by RH, abs humidity, temp, season for FRM}
#plot.grav.corr2(frm)

#tables of curves by: rh, abs hum, temp
write_clip(table.grav.corr2.season(frm))
write_clip(table.grav.corr2.ah(frm)) #estimated 

# season.ah.rh <- data.frame( Season = unique(frm$Season.x), MedianAbsHum= rep(NA, 4), MedianRH= rep(NA, 4))
# for (i in 1:length(season.ah$Season)){
#   df1 <- frm[frm$Season.x==season.ah$Season[i],]
#   season.ah$MedianAbsHum[i] <- round(median(df1$SeaTac_AbsHum_g_m3.x, na.rm = T),1)
#   season.ah$MedianRH[i] <- round(median(df1$SeaTac_RH.x, na.rm = T),1)
# }

write_clip(table.grav.corr2.rh(frm))
write_clip(table.grav.corr2.temp(frm))

#write_clip(season.ah)

```


Table: Calibration Curve by station, year & Absolute humidity
-long dataset using FRM
```{r table4a FRM station, year, AH corr}
#round AH to create 15 discrete values
frm$AH_g_m3 <- round(frm$SeaTac_AbsHum_g_m3.x)
stat.yr <- unique(frm[c("StationCode", "Location", "Year.x", "AH_g_m3")])
#remove data w/o AH
stat.yr <- stat.yr[!is.na(stat.yr$AH),]

table4a <- data.frame(Station=stat.yr$StationCode,
                     Location=stat.yr$Location,
                      Year=stat.yr$Year.x,
                     AH = stat.yr$AH_g_m3,
                     Pairs=rep(NA, length(stat.yr$StationCode)),
                     slope=rep(NA, length(stat.yr$StationCode)),
                     int= rep(NA, length(stat.yr$StationCode)),
                     R2=rep(NA, length(stat.yr$StationCode)))
#estimate pairs
for(i in 1:length(table4a$Station)){
  df <-frm[c(frm$StationCode==table4a$Station[i] & frm$Year.x ==table4a$Year[i] & round(frm$SeaTac_AbsHum_g_m3.x) == table4a$AH[i]), ]

  lm.df <- summary(lm(Grav.Avg~LS.Avg, data=df))
  table4a$Pairs[i] <- length(df$ObservedDate)}
#exclude data w/ too few observations (20)
table4a <- table4a[table4a$Pairs >20,]

#estimate AH categories from available data: RH 4-12
table4a$AH_cat <- factor(ifelse(table4a$AH >=4 & table4a$AH <=6, "4_6", ifelse(table4a$AH >=7 & table4a$AH <=9, "7_9", ifelse(table4a$AH >=10 & table4a$AH <=12, "10_12", NA))), levels = c("4_6", "7_9", "10_12")) 


#estimate slope, int, R2
for(i in 1:length(table4a$Station)){
  df <-frm[c(frm$StationCode==table4a$Station[i] & frm$Year.x ==table4a$Year[i] & round(frm$SeaTac_AbsHum_g_m3.x) == table4a$AH[i]), ]

    lm.df <- summary(lm(Grav.Avg~LS.Avg, data=df))
  
  table4a$slope[i] <- lm.df$coefficients[2,1]
  table4a$int[i] <- lm.df$coefficients[1,1]
  table4a$R2[i] <- lm.df$r.squared
}

#get FRM calibration curve values for centering
frm.lm <- summary(lm(data=frm, Grav.Avg~LS.Avg))
frm.B0 <- frm.lm$coefficients[1,1]
frm.B1 <- frm.lm$coefficients[2,1]
frm.R2 <- frm.lm$r.squared

table4a$slope.centered <- round(table4a$slope - frm.B1, 2)
table4a$int.centered <- round(table4a$int - frm.B0, 2)
table4a$R2.centered <- round(table4a$R2 - frm.R2, 2)

#make year categories and a factor 
table4a$Year.cat <- factor(ifelse(table4a$Year >= 1998 & table4a$Year <= 2002, "1998_2002", ifelse(table4a$Year >= 2003 & table4a$Year <= 2007, "2003_2007", ifelse(table4a$Year >= 2008 & table4a$Year <= 2012, "2008_2012", ifelse(table4a$Year >= 2013 & table4a$Year < 2017, "2013_2017", NA)))), levels = c("1998_2002", "2003_2007", "2008_2012", "2013_2017"))

table4a$Year <- as.factor(table4a$Year)

#rearrange columns
table4a <- table4a[c("Station", "Location", "Year", "Year.cat", "AH", "AH_cat", "Pairs", "slope", "int", "R2", "slope.centered", "int.centered", "R2.centered")]

#write_clip(table4a)
```

-what factors influence slope, int, R2?
```{r slope}
#slope.cent ~ Year
summary(lm(data=table4a, slope.centered~ Year)) 
lm1 <- data.frame(summary(lm(data=table4a, slope.centered ~ Year))$coef)
lm1$var <- rownames(lm1)
lm1 <- lm1[c(5, 1:4)]
#write_clip(lm1)

#slope.cent ~ AH
summary(lm(data=table4a, slope.centered~ AH)) 
lm1 <- data.frame(summary(lm(data=table4a, slope.centered ~ AH))$coef)
lm1$var <- rownames(lm1)
lm1 <- lm1[c(5, 1:4)]
#write_clip(lm1)

#slope.cent ~ AH_cat
summary(lm(data=table4a, slope.centered~ AH_cat)) 
lm1 <- data.frame(summary(lm(data=table4a, slope.centered ~ AH_cat))$coef)
lm1$var <- rownames(lm1)
lm1 <- lm1[c(5, 1:4)]
#write_clip(lm1)


#slope.cent ~ Location
summary(lm(data=table4a, slope.centered~ Location)) 
lm1 <- data.frame(summary(lm(data=table4a, slope.centered ~ Location))$coef)
lm1$var <- rownames(lm1)
lm1 <- lm1[c(5, 1:4)]
#write_clip(lm1)
```

```{r int}
#int.cent ~ Year
summary(lm(data=table4a, int.centered~ Year)) 
lm1 <- data.frame(summary(lm(data=table4a, int.centered ~ Year))$coef)
lm1$var <- rownames(lm1)
lm1 <- lm1[c(5, 1:4)]
#write_clip(lm1)

#int.cent ~ AH
summary(lm(data=table4a, int.centered~ AH)) 
lm1 <- data.frame(summary(lm(data=table4a, int.centered ~ AH))$coef)
lm1$var <- rownames(lm1)
lm1 <- lm1[c(5, 1:4)]
#write_clip(lm1)

#int.cent ~ AH_cat
summary(lm(data=table4a, int.centered~ AH_cat)) 
lm1 <- data.frame(summary(lm(data=table4a, int.centered ~ AH_cat))$coef)
lm1$var <- rownames(lm1)
lm1 <- lm1[c(5, 1:4)]
#write_clip(lm1)

#int.cent ~ Location
summary(lm(data=table4a, int.centered~ Location)) 
lm1 <- data.frame(summary(lm(data=table4a, int.centered ~ Location))$coef)
lm1$var <- rownames(lm1)
lm1 <- lm1[c(5, 1:4)]
#write_clip(lm1)
```

```{r R2}
#R2.cent ~ Year
summary(lm(data=table4a, R2.centered~ Year)) 
lm1 <- data.frame(summary(lm(data=table4a, R2.centered ~ Year))$coef)
lm1$var <- rownames(lm1)
lm1 <- lm1[c(5, 1:4)]
#write_clip(lm1)

#R2.cent ~ AH
summary(lm(data=table4a, R2.centered~ AH)) 
lm1 <- data.frame(summary(lm(data=table4a, R2.centered ~ AH))$coef)
lm1$var <- rownames(lm1)
lm1 <- lm1[c(5, 1:4)]
#write_clip(lm1)

#R2.cent ~ AH_cat
summary(lm(data=table4a, R2.centered~ AH_cat)) 
lm1 <- data.frame(summary(lm(data=table4a, R2.centered ~ AH_cat))$coef)
lm1$var <- rownames(lm1)
lm1 <- lm1[c(5, 1:4)]
#write_clip(lm1)

#R2.cent ~ Location
summary(lm(data=table4a, R2.centered~ Location)) 
lm1 <- data.frame(summary(lm(data=table4a, R2.centered ~ Location))$coef)
lm1$var <- rownames(lm1)
lm1 <- lm1[c(5, 1:4)]
#write_clip(lm1)
```




 
